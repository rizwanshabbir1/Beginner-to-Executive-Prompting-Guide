First,
 
be
 
conscious
 
of
 
data
 
leakage
 
through
 
prompts.
 
Every
 
piece
 
of
 
information
 
you
 
include
 
in
 
a
 
prompt
 
to
 
an
 
AI
 
system
 
could
 
potentially
 
be
 
exposed.
 
This
 
includes
 
customer
 
data,
 
employee
 
information,
 
financial
 
details,
 
or
 
strategic
 
plans.
 
Before
 
sharing
 
information
 
with
 
an
 
AI
 
system,
 
ask
 
yourself:
 
"Would
 
I
 
be
 
comfortable
 
with
 
this
 
information
 
appearing
 
on
 
a
 
public
 
website?"
 
If
 
not,
 
reconsider
 
what
 
you're
 
sharing.
 
Second,
 
understand
 
that
 
AI
 
systems
 
can
 
sometimes
 
reveal
 
their
 
training
 
data.
 
This
 
phenomenon,
 
known
 
as
 
"training
 
data
 
extraction,"
 
means
 
that
 
with
 
carefully
 
crafted
 
prompts,
 
someone
 
may
 
be
 
able
 
to
 
extract
 
the
 
actual
 
content
 
on
 
which
 
the
 
AI
 
was
 
trained.
 
If
 
your
 
organization's
 
confidential
 
information
 
was
 
inadvertently
 
included
 
in
 
that
 
training
 
data,
 
it
 
could
 
potentially
 
be
 
extracted.
 
Third,
 
recognize
 
that
 
interactions
 
with
 
AI
 
are
 
often
 
more
 
permanent
 
than
 
conversations
 
with
 
colleagues.
 
While
 
a
 
verbal
 
question
 
to
 
a
 
coworker
 
disappears
 
after
 
it's
 
answered,
 
information
 
shared
 
with
 
AI
 
systems
 
may
 
be
 
logged
 
and
 
stored
 
according
 
to
 
the
 
vendor's
 
data
 
retention
 
policies.
 
This
 
creates
 
a
 
longer
 
vulnerability
 
window
 
for
 
sensitive
 
information.
 
Fourth,
 
consider
 
access
 
controls.
 
Who
 
in
 
your
 
organization
 
can
 
utilize
 
AI
 
tools,
 
and
 
what
 
guardrails
 
are
 
in
 
place?
 
Unrestricted
 
access
 
without
 
proper
 
training
 
increases
 
risk.
 
Just
 
as
 
you
 
wouldn't
 
give
 
everyone
 
admin
 
access
 
to
 
critical
 
systems,
 
consider
 
appropriate
 
access
 
levels
 
for
 
powerful
 
AI
 
tools.
 
Take
 
a
 
moment
 
to
 
reflect:
 
What
 
types
 
of
 
information
 
have
 
you
 
or
 
your
 
colleagues
 
shared
 
with
 
AI
 
systems
 
recently?
 
Would
 
any
 
of
 
that
 
information
 
be
 
concerning
 
if
 
it
 
were
 
exposed
 
outside
 
your
 
organization?
 
UNINTENDED
 
CONSEQUENCES
 
OF
 
AI
 
IMPLEMENT ATION
 
 
Security
 
isn't
 
just
 
about
 
data
 
protectionâ€”it
 
also
 
involves
 
understanding
 
broader
 
risks
 
and
 
unintended
 
consequences
 
of
 
AI
 
use.
 
Automation
 
bias
 
is
 
a
 
significant
 
concern.
 
This
 
occurs
 
when
 
people
 
give
 
undue
 
weight
 
to
 
AI-generated
 
information
 
simply
 
because
 
it
 
appears
 
to
 
come
 
from
 
a
 
seemingly
 
objective
 
computer
 
system.
 
In
 
business
 
contexts,
 
this
 
can
 
lead
 
to
 
a
 
decrease
 
in
 
critical
 
thinking
 
and
 
an
 
over-reliance
 
on
 
AI
 
recommendations
 
without
 
proper
 
scrutiny .
 
Remember
 
that
 
AI
 
tools
 
are
 
designed
 
to
 
be
 
helpful
 
and
 
provide
 
answers
 
even
 
when
 
they
 
should
 
express
 
uncertainty .
 
There's
 
also
 
the
 
risk
 
of
 
skill
 
atrophy .
 
As
 
teams
 
become
 
increasingly
 
dependent
 
on
 
AI
 
for
 
tasks
 
such
 
as
 
writing,
 
analysis,
 
or
 
creative
 
work,
 
they
 
may
 
lose
 
proficiency
 
in
 
these
 
fundamental
 
skills.
 
Organizations
 
should
 
consider
 
which
 
capabilities
 
need
 
to
 
be
 
maintained
 
internally ,
 
regardless
 
of
 
the
 
advancement
 
of
 
AI.
 
215
 
 